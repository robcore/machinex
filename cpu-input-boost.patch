From fef657060bd3fc1640fe7885d93b23f271801fed Mon Sep 17 00:00:00 2001
From: Sultanxda <sultanxda@gmail.com>
Date: Tue, 21 Apr 2015 19:31:21 -0700
Subject: [PATCH] cpufreq: Introduce CPU input boost driver

This boosts the CPU on touchscreen and touchpad input. Boost frequencies, durations, and number of CPUs to boost are calculated automatically using fudge factors. The only configuration required for functionality is to enable boosting via the /sys/module/cpu_input_boost/parameters/enabled sysfs node.

Signed-off-by: Sultanxda <sultanxda@gmail.com>
Signed-off-by: Paul Keith <javelinanddart@gmail.com>

cpufreq: Disable CAF cpu-boost driver

*Replaced by CPU input boost driver

cpu_input_boost: Prioritize primary CPU

*Primary CPU (CPU0) is boosted more than the other CPUs, and it is boosted for longer
*The boost speed and duration are reduced for the secondary CPU and even more so for the tertiary CPU

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Replace auto-freq finder with sysfs interface

*To change boost freqs, write 3 valid, different CPU frequencies to /sys/kernel/cpu_input_boost/boost_freqs. Ex: echo "1574400 1036800 1190400" > /sys/kernel/cpu_input_boost/boost_freqs
*Moved other sysfs-exposed variables (enabled and up_threshold) all to the same directory for the sake of consistency

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Specify some variables as read-mostly

cpu_input_boost: Use spinlocks instead of mutex locks

*Sleeping in the notifier could cause problems in cpufreq

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Make long function names shorter and more consistent

*This bothered me way more than it should have

cpu_input_boost: Remove spin locks

*These aren't necessary

cpu_input_boost: Remove cpufreq get/put API usage

*These are internal functions that shouldn't be used outside of cpufreq

cpu_input_boost: Remove redundant calculations and logic

*This logic was redundant and didn't fulfill its original purpose
*The number of CPUs to boost is now the number of CPUs online minus one
*Removed any semblance of dual-core support (this new logic only works well on quad-core devices)

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Update boost duration equation

*Scales way better now
*Saves power (boost durations can't be absurdly long now)

cpu_input_boost: Add support for userspace control

*Userspace can override/disable input boosting via the userspace_minfreq sysfs node
*Userspace can force a certain minfreq to be used

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Run all workers on CPU0

*Workers cannot be reentrant on the same CPU
*Prevents possible synchronization issues

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Minor clean-up in notifier

cpu_input_boost: Remove deprecated sprintf usage

cpu_input_boost: Clean up and fix bugs

*Removed derpy user_minfreq feature
*Fixed bug where too few CPUs were boosted (fewer than nr_cpus_to_boost were boosted)
*Fixed boost duration equation (it would calculate a negative boost duration sometimes, but it didn't cause actual errors because nr_cpus_to_boost is unsigned)

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Boost on framebuffer blank/unblank

*Boosts all online CPUs to policy->max for 500ms on framebuffer blank/unblank
*Takes precedence and overrides regular boosts

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Add boosting on thread migration

*Originally from CAF's cpu-boost driver, adapted to this driver
*Renamed variables and refactored all of the code to make things less confusing
*Added sysfs controls for thread-migration boosting

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Remove boost on framebuffer blank

There was a bug that caused the minfreq of the CPU to get stuck at policy->max while the screen was off and the CPU was awake. The bug is fixed now (see the change to fb_boost_fn()), but boosting on fb blank is too risky and not worth it, so remove it.

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Remove input-boost frequency limitations

Allow any boost frequency for any CPU.

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Reduce input-boost duration

TODO: Make the input-boost duration equation more standard and configurable from sysfs.

cpu_input_boost: Increase unblank-boost duration to 900ms

cpu_input_boost: Rewrite to use dual-core boosting and clean up

Previously, up to 3 CPUs could boosted at any given time; now, only 2 CPUs
can be boosted. With the new logic, 2 CPUs are boosted when only 1 is online,
and 1 CPU is boosted when there is more than 1 CPU online. This new logic
assumes that when only 1 CPU is online, a 2nd CPU will come online shortly
after due to user interaction, and that newly-onlined CPU will be boosted.
If a 2nd CPU isn't enabled within the time frame of the CPU0's boost, then
only CPU0 will have been boosted. If a 2nd CPU does come online within CPU0's
boost time frame, then it will be boosted for the remaining time left on
CPU0's boost (minus 10ms to eliminate any trivial racing between the
restoration workers).

Boost duration now uses a single variable exposed in sysfs. The user-set
boost duration is reduced by a factor of (1 + num_online_cpus())/(3 + num_online_cpus()).
In other words, when there are more CPUs online, the boost duration is
shorter.

Various functions and variables have been renamed for clarity, and other
parts of the code have been cleaned up as well.

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Remove sync_threshold to recover from regression

Load-based syncs successfully avoid boosting of lightweight threads.
Unfortunately, CPUs with high frequencies over sync_threshold will
be unnaturally throttled which becomes apparent in hackbench with
its high number of thread migrations. None of the newer targets sets
sync_threshold, either.

Pre patch:
root@hammerhead:/ # perf stat --repeat 10 hackbench 10
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.923
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 1.106
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.934
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.917
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.765
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.807
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.930
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.937
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.858
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.808

 Performance counter stats for 'hackbench 10  ' (10 runs):

   3575.129450 task-clock#3.498 CPUs utilized
 ( +-  3.95% )
 42637 context-switches  #0.012 M/sec
 ( +- 12.54% )
  6152 CPU-migrations#0.002 M/sec
 ( +-  9.98% )
 37874 page-faults   #0.011 M/sec
 ( +-  0.02% )
6208354174 cycles#1.737 GHz <--- should not happen!
 ( +-  1.78% ) [90.87%]
 0 stalled-cycles-frontend   #0.00% frontend cycles idle
 ( +-  0.00% ) [88.02%]
 0 stalled-cycles-backend#0.00% backend  cycles idle
 ( +-  0.00% ) [87.13%]
1948037598 instructions  #0.31  insns per cycle
 ( +-  1.53% ) [89.32%]
 203196136 branches  #   56.836 M/sec
 ( +-  1.46% ) [90.70%]
   5345440 branch-misses #2.63% of all branches
 ( +-  4.62% ) [85.52%]

   1.022038466 seconds time elapsed
 ( +-  4.09% )

Post patch:
root@hammerhead:/ # perf stat --repeat 10 hackbench 10
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.735
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.815
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.754
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.721
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.770
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.767
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.762
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.689
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.748
Running in process mode with 10 groups using 40 file descriptors each (== 400 tasks)
Each sender will pass 100 messages of 100 bytes
Time: 0.679

 Performance counter stats for 'hackbench 10  ' (10 runs):

   2838.930889 task-clock#3.343 CPUs utilized
 ( +-  1.81% )
 22301 context-switches  #0.008 M/sec
 ( +- 11.18% )
  3641 CPU-migrations#0.001 M/sec
 ( +- 11.13% )
 37950 page-faults   #0.013 M/sec
 ( +-  0.09% )
5714558403 cycles#2.013 GHz
 ( +-  1.59% ) [91.42%]
 0 stalled-cycles-frontend   #0.00% frontend cycles idle
 ( +-  0.00% ) [89.07%]
 0 stalled-cycles-backend#0.00% backend  cycles idle
 ( +-  0.00% ) [89.74%]
1868219180 instructions  #0.33  insns per cycle
 ( +-  0.82% ) [90.90%]
 193711678 branches  #   68.234 M/sec
 ( +-  1.44% ) [91.41%]
   4927373 branch-misses #2.54% of all branches
 ( +-  3.57% ) [87.20%]

   0.849242812 seconds time elapsed
 ( +-  1.58% )

Change-Id: I8744cc1f96fefa81149ded1c2dc54ff4d3b76665

cpu_input_boost: Remove thread-migration boosting and clean up

Thread migrations occur far too often for boosting on thread-migration to be
battery-efficient. Even with load-based syncs implemented, frequent migration
boosts caused excessive heating and battery drain (especially during streaming
video playback).

Remove thread-migration (as it will never be used) and clean up the code that
remains. The framebuffer boost/unboost code has been split into their own
respective workers, comments have been added, and variables have been renamed
for consistency.

Signed-off-by: Sultanxda <sultanxda@gmail.com>

cpu_input_boost: Remove module references

This isn't a module.
---
 drivers/cpufreq/Kconfig           |   6 +
 drivers/cpufreq/Makefile          |   5 +-
 drivers/cpufreq/cpu_input_boost.c | 479 ++++++++++++++++++++++++++++++++++++++
 3 files changed, 489 insertions(+), 1 deletion(-)
 create mode 100644 drivers/cpufreq/cpu_input_boost.c

diff --git a/drivers/cpufreq/Kconfig b/drivers/cpufreq/Kconfig
index 8fb8653..3e15360 100644
--- a/drivers/cpufreq/Kconfig
+++ b/drivers/cpufreq/Kconfig
@@ -216,6 +216,12 @@ config SEC_DVFS_BOOSTER
     default y
     depends on SEC_DVFS
 
+config CPU_INPUT_BOOST
+	bool "CPU Input Boost"
+	help
+	  Boosts the CPU on touchscreen and touchpad input. Boost frequencies and
+	  duration are configured via sysfs (/sys/kernel/cpu_input_boost/*).
+
 menu "x86 CPU frequency scaling drivers"
 depends on X86
 source "drivers/cpufreq/Kconfig.x86"
diff --git a/drivers/cpufreq/Makefile b/drivers/cpufreq/Makefile
index 83ab92b..1d07a4a 100644
--- a/drivers/cpufreq/Makefile
+++ b/drivers/cpufreq/Makefile
@@ -1,5 +1,5 @@
 # CPUfreq core
-obj-$(CONFIG_CPU_FREQ)			+= cpufreq.o
+obj-$(CONFIG_CPU_FREQ)			+= cpufreq.o
 # CPUfreq stats
 obj-$(CONFIG_CPU_FREQ_STAT)             += cpufreq_stats.o
 
@@ -11,6 +11,9 @@ obj-$(CONFIG_CPU_FREQ_GOV_ONDEMAND)	+= cpufreq_ondemand.o
 obj-$(CONFIG_CPU_FREQ_GOV_CONSERVATIVE)	+= cpufreq_conservative.o
 obj-$(CONFIG_CPU_FREQ_GOV_INTERACTIVE)	+= cpufreq_interactive.o
 
+# CPU Input Boost
+obj-$(CONFIG_CPU_INPUT_BOOST)		+= cpu_input_boost.o
+
 # CPUfreq cross-arch helpers
 obj-$(CONFIG_CPU_FREQ_TABLE)		+= freq_table.o
 
diff --git a/drivers/cpufreq/cpu_input_boost.c b/drivers/cpufreq/cpu_input_boost.c
new file mode 100644
index 0000000..58eb053
--- /dev/null
+++ b/drivers/cpufreq/cpu_input_boost.c
@@ -0,0 +1,479 @@
+/*
+ * Copyright (C) 2014-2015, Sultanxda <sultanxda@gmail.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "CPU-iboost: " fmt
+
+#include <linux/cpu.h>
+#include <linux/cpufreq.h>
+#include <linux/fb.h>
+#include <linux/input.h>
+#include <linux/slab.h>
+
+#define FB_BOOST_MS 900
+
+enum boost_status {
+	UNBOOST,
+	BOOST,
+};
+
+struct boost_policy {
+	struct delayed_work ib_unboost_work;
+	enum boost_status boost_state;
+	unsigned int cpu;
+};
+
+static DEFINE_PER_CPU(struct boost_policy, boost_info);
+static struct workqueue_struct *boost_wq;
+static struct work_struct fb_boost_work;
+static struct delayed_work fb_unboost_work;
+static struct work_struct ib_boost_work;
+
+static bool ib_running;
+static enum boost_status fb_boost;
+static u64 boost_start_time;
+static unsigned int enabled;
+static unsigned int ib_adj_duration_ms;
+static unsigned int ib_duration_ms;
+static unsigned int ib_freq[2];
+static unsigned int ib_nr_cpus_boosted;
+static unsigned int ib_nr_cpus_to_boost;
+
+/* Boost function for input boost (only for CPU0) */
+static void boost_cpu0(unsigned int duration_ms)
+{
+	struct boost_policy *b = &per_cpu(boost_info, 0);
+
+	b->boost_state = BOOST;
+	ib_nr_cpus_boosted++;
+	cpufreq_update_policy(0);
+	queue_delayed_work(boost_wq, &b->ib_unboost_work,
+				msecs_to_jiffies(duration_ms));
+
+	/* Record start time for use if a 2nd CPU to be boosted comes online */
+	boost_start_time = ktime_to_ms(ktime_get());
+}
+
+/* Unboost function for input boost */
+static void unboost_cpu(unsigned int cpu)
+{
+	struct boost_policy *b = &per_cpu(boost_info, cpu);
+
+	b->boost_state = UNBOOST;
+	get_online_cpus();
+	if (cpu_online(b->cpu))
+		cpufreq_update_policy(b->cpu);
+	put_online_cpus();
+}
+
+static void unboost_all_cpus(void)
+{
+	struct boost_policy *b;
+	unsigned int cpu;
+
+	get_online_cpus();
+	for_each_possible_cpu(cpu) {
+		b = &per_cpu(boost_info, cpu);
+		b->boost_state = UNBOOST;
+		if (cpu_online(cpu))
+			cpufreq_update_policy(cpu);
+	}
+	put_online_cpus();
+
+	ib_running = false;
+}
+
+/* Stops everything and unboosts all CPUs */
+static void stop_all_boosts(void)
+{
+	/* Make sure input-boost and framebuffer boost are not running */
+	cancel_work_sync(&fb_boost_work);
+	cancel_work_sync(&ib_boost_work);
+
+	fb_boost = UNBOOST;
+	unboost_all_cpus();
+}
+
+/* Main input boost worker */
+static void __cpuinit ib_boost_main(struct work_struct *work)
+{
+	get_online_cpus();
+
+	ib_nr_cpus_boosted = 0;
+
+	/*
+	 * Maximum of two CPUs can be boosted at any given time.
+	 * Boost two CPUs if only one is online as it's very likely
+	 * that another CPU will come online soon (due to user interaction).
+	 * The next CPU to come online is the other CPU that will be boosted.
+	 */
+	ib_nr_cpus_to_boost = num_online_cpus() == 1 ? 2 : 1;
+
+	/*
+	 * Reduce the boost duration for all CPUs by a factor of
+	 * (1 + num_online_cpus())/(3 + num_online_cpus()).
+	 */
+	ib_adj_duration_ms = ib_duration_ms * 3 / (3 + num_online_cpus());
+
+	/*
+	 * Only boost CPU0 from here. More than one CPU is only boosted when
+	 * the 2nd CPU to boost is offline at this point in time, so the boost
+	 * notifier will handle boosting the 2nd CPU if/when it comes online.
+	 *
+	 * Add 10ms to CPU0's duration to prevent trivial racing with the
+	 * 2nd CPU's restoration worker (if a 2nd CPU is indeed boosted).
+	 */
+	boost_cpu0(ib_adj_duration_ms + 10);
+
+	put_online_cpus();
+}
+
+/* Main unboost worker for input boost */
+static void __cpuinit ib_unboost_main(struct work_struct *work)
+{
+	struct boost_policy *b = container_of(work, struct boost_policy,
+							ib_unboost_work.work);
+	unsigned int cpu;
+
+	unboost_cpu(b->cpu);
+
+	/* Check if all boosts are finished */
+	for_each_possible_cpu(cpu) {
+		b = &per_cpu(boost_info, cpu);
+		if (b->boost_state == BOOST)
+			return;
+	}
+
+	/* All input boosts are done, ready to accept new boosts now */
+	ib_running = false;
+}
+
+/* Framebuffer-boost worker */
+static void __cpuinit fb_boost_main(struct work_struct *work)
+{
+	unsigned int cpu;
+
+	/* All CPUs will be boosted to policy->max */
+	fb_boost = BOOST;
+
+	/* Immediately boost the online CPUs to policy->max */
+	get_online_cpus();
+	for_each_online_cpu(cpu)
+		cpufreq_update_policy(cpu);
+	put_online_cpus();
+
+	queue_delayed_work(boost_wq, &fb_unboost_work,
+				msecs_to_jiffies(FB_BOOST_MS));
+}
+
+/* Framebuffer-unboost worker */
+static void __cpuinit fb_unboost_main(struct work_struct *work)
+{
+	fb_boost = UNBOOST;
+	unboost_all_cpus();
+}
+
+/* Notifier used to actually perform the boosts/unboosts */
+static int do_cpu_boost(struct notifier_block *nb, unsigned long val, void *data)
+{
+	struct cpufreq_policy *policy = data;
+	struct boost_policy *b = &per_cpu(boost_info, policy->cpu);
+
+	if (!enabled && policy->min == policy->cpuinfo.min_freq)
+		return NOTIFY_OK;
+
+	if (val != CPUFREQ_ADJUST)
+		return NOTIFY_OK;
+
+	if (fb_boost) {
+		policy->min = policy->max;
+		return NOTIFY_OK;
+	}
+
+	/* Boost previously-offline CPU */
+	if (ib_nr_cpus_boosted < ib_nr_cpus_to_boost &&
+		policy->cpu && !b->boost_state) {
+		int duration_ms = ib_adj_duration_ms -
+			(ktime_to_ms(ktime_get()) - boost_start_time);
+		if (duration_ms > 0) {
+			b->boost_state = BOOST;
+			ib_nr_cpus_boosted++;
+			queue_delayed_work(boost_wq, &b->ib_unboost_work,
+						msecs_to_jiffies(duration_ms));
+		}
+	}
+
+	if (b->boost_state)
+		policy->min = min(policy->max, ib_freq[policy->cpu ? 1 : 0]);
+	else
+		policy->min = policy->cpuinfo.min_freq;
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block do_cpu_boost_nb = {
+	.notifier_call = do_cpu_boost,
+};
+
+/* Framebuffer-boost notifier; CPU is boosted when device wakes up */
+static int fb_unblank_boost(struct notifier_block *nb, unsigned long val, void *data)
+{
+	struct fb_event *evdata = data;
+	int *blank = evdata->data;
+
+	if (!enabled)
+		return NOTIFY_OK;
+
+	/* Only boost on fb blank events */
+	if (val != FB_EVENT_BLANK)
+		return NOTIFY_OK;
+
+	/* Only boost for unblank */
+	if (*blank != FB_BLANK_UNBLANK)
+		return NOTIFY_OK;
+
+	/* Framebuffer boost is already in progress */
+	if (fb_boost)
+		return NOTIFY_OK;
+
+	queue_work(boost_wq, &fb_boost_work);
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block fb_boost_nb = {
+	.notifier_call = fb_unblank_boost,
+};
+
+/* Input event handler; this is where input boosts start */
+static void cpu_ib_input_event(struct input_handle *handle, unsigned int type,
+		unsigned int code, int value)
+{
+	if (ib_running || !enabled || fb_boost)
+		return;
+
+	/* Indicate that an input-boost event is in progress */
+	ib_running = true;
+
+	queue_work(boost_wq, &ib_boost_work);
+}
+
+static int cpu_ib_input_connect(struct input_handler *handler,
+		struct input_dev *dev, const struct input_device_id *id)
+{
+	struct input_handle *handle;
+	int error;
+
+	handle = kzalloc(sizeof(struct input_handle), GFP_KERNEL);
+	if (!handle)
+		return -ENOMEM;
+
+	handle->dev = dev;
+	handle->handler = handler;
+	handle->name = "cpu_iboost";
+
+	error = input_register_handle(handle);
+	if (error)
+		goto err2;
+
+	error = input_open_device(handle);
+	if (error)
+		goto err1;
+
+	return 0;
+err1:
+	input_unregister_handle(handle);
+err2:
+	kfree(handle);
+	return error;
+}
+
+static void cpu_ib_input_disconnect(struct input_handle *handle)
+{
+	input_close_device(handle);
+	input_unregister_handle(handle);
+	kfree(handle);
+}
+
+static const struct input_device_id cpu_ib_ids[] = {
+	/* multi-touch touchscreen */
+	{
+		.flags = INPUT_DEVICE_ID_MATCH_EVBIT |
+			INPUT_DEVICE_ID_MATCH_ABSBIT,
+		.evbit = { BIT_MASK(EV_ABS) },
+		.absbit = { [BIT_WORD(ABS_MT_POSITION_X)] =
+			BIT_MASK(ABS_MT_POSITION_X) |
+			BIT_MASK(ABS_MT_POSITION_Y) },
+	},
+	/* touchpad */
+	{
+		.flags = INPUT_DEVICE_ID_MATCH_KEYBIT |
+			INPUT_DEVICE_ID_MATCH_ABSBIT,
+		.keybit = { [BIT_WORD(BTN_TOUCH)] = BIT_MASK(BTN_TOUCH) },
+		.absbit = { [BIT_WORD(ABS_X)] =
+			BIT_MASK(ABS_X) | BIT_MASK(ABS_Y) },
+	},
+	{ },
+};
+
+static struct input_handler cpu_ib_input_handler = {
+	.event		= cpu_ib_input_event,
+	.connect	= cpu_ib_input_connect,
+	.disconnect	= cpu_ib_input_disconnect,
+	.name		= "cpu_iboost",
+	.id_table	= cpu_ib_ids,
+};
+
+/**************************** SYSFS START ****************************/
+static struct kobject *cpu_ib_kobject;
+
+static ssize_t enabled_write(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t size)
+{
+	unsigned int data;
+	int ret = sscanf(buf, "%u", &data);
+
+	if (ret != 1)
+		return -EINVAL;
+
+	enabled = data;
+
+	/* Ensure that everything is stopped when returning from here */
+	if (!enabled)
+		stop_all_boosts();
+
+	return size;
+}
+
+static ssize_t ib_freqs_write(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t size)
+{
+	unsigned int freq[2];
+	int ret = sscanf(buf, "%u %u", &freq[0], &freq[1]);
+
+	if (ret != 2)
+		return -EINVAL;
+
+	if (!freq[0] || !freq[1])
+		return -EINVAL;
+
+	/* ib_freq[0] is assigned to CPU0, ib_freq[1] to CPUX (X > 0) */
+	ib_freq[0] = freq[0];
+	ib_freq[1] = freq[1];
+
+	return size;
+}
+
+static ssize_t ib_duration_ms_write(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t size)
+{
+	unsigned int ms;
+	int ret = sscanf(buf, "%u", &ms);
+
+	if (ret != 1)
+		return -EINVAL;
+
+	if (!ms)
+		return -EINVAL;
+
+	ib_duration_ms = ms;
+
+	return size;
+}
+
+static ssize_t enabled_read(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%u\n", enabled);
+}
+
+static ssize_t ib_freqs_read(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%u %u\n",
+				ib_freq[0], ib_freq[1]);
+}
+
+static ssize_t ib_duration_ms_read(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%u\n", ib_duration_ms);
+}
+
+static DEVICE_ATTR(enabled, 0644,
+			enabled_read, enabled_write);
+static DEVICE_ATTR(ib_freqs, 0644,
+			ib_freqs_read, ib_freqs_write);
+static DEVICE_ATTR(ib_duration_ms, 0644,
+			ib_duration_ms_read, ib_duration_ms_write);
+
+static struct attribute *cpu_ib_attr[] = {
+	&dev_attr_enabled.attr,
+	&dev_attr_ib_freqs.attr,
+	&dev_attr_ib_duration_ms.attr,
+	NULL
+};
+
+static struct attribute_group cpu_ib_attr_group = {
+	.attrs  = cpu_ib_attr,
+};
+/**************************** SYSFS END ****************************/
+
+static int __init cpu_ib_init(void)
+{
+	struct boost_policy *b;
+	int cpu, ret;
+
+	boost_wq = alloc_workqueue("cpu_ib_wq", WQ_HIGHPRI | WQ_NON_REENTRANT, 0);
+	if (!boost_wq) {
+		pr_err("Failed to allocate workqueue\n");
+		ret = -EFAULT;
+		goto err;
+	}
+
+	cpufreq_register_notifier(&do_cpu_boost_nb, CPUFREQ_POLICY_NOTIFIER);
+
+	INIT_DELAYED_WORK(&fb_unboost_work, fb_unboost_main);
+
+	INIT_WORK(&fb_boost_work, fb_boost_main);
+
+	fb_register_client(&fb_boost_nb);
+
+	for_each_possible_cpu(cpu) {
+		b = &per_cpu(boost_info, cpu);
+		b->cpu = cpu;
+		INIT_DELAYED_WORK(&b->ib_unboost_work, ib_unboost_main);
+	}
+
+	INIT_WORK(&ib_boost_work, ib_boost_main);
+
+	ret = input_register_handler(&cpu_ib_input_handler);
+	if (ret) {
+		pr_err("Failed to register input handler, err: %d\n", ret);
+		goto err;
+	}
+
+	cpu_ib_kobject = kobject_create_and_add("cpu_input_boost", kernel_kobj);
+	if (!cpu_ib_kobject) {
+		pr_err("Failed to create kobject\n");
+		goto err;
+	}
+
+	ret = sysfs_create_group(cpu_ib_kobject, &cpu_ib_attr_group);
+	if (ret) {
+		pr_err("Failed to create sysfs interface\n");
+		kobject_put(cpu_ib_kobject);
+	}
+err:
+	return ret;
+}
+late_initcall(cpu_ib_init);
